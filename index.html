<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>Extended CUDA Library (ecuda): Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<link href="customdoxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">Extended CUDA Library (ecuda)
   &#160;<span id="projectnumber">2.0</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Macros</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Extended CUDA Library (ecuda) Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#intro">Overview</a></li>
<li class="level1"><a href="#quick_ref">A Few Things You Should Know</a><ul><li class="level2"><a href="#quick_ref_kernels">Containers as Kernel Arguments</a></li>
<li class="level2"><a href="#quick_ref_ops">Direct Access Operators</a></li>
<li class="level2"><a href="#quick_ref_contiguity">Memory Contiguity</a></li>
<li class="level2"><a href="#quick_ref_macros">Macros</a></li>
<li class="level2"><a href="#quick_ref_hostemu">Host Emulation</a></li>
</ul>
</li>
<li class="level1"><a href="#example">Core Concepts and Examples</a><ul><li class="level2"><a href="#example_array">Arrays</a></li>
<li class="level2"><a href="#example_vector">Vectors</a></li>
<li class="level2"><a href="#example_matrix">Matrices</a></li>
<li class="level2"><a href="#example_cube">Cubes</a></li>
<li class="level2"><a href="#example_host_alloc">Allocators</a></li>
<li class="level2"><a href="#example_exception">Exceptions</a></li>
<li class="level2"><a href="#example_events">Events</a></li>
</ul>
</li>
<li class="level1"><a href="#faq">Frequently Asked Questions</a><ul><li class="level2"><a href="#faq_thrust">Why not Thrust?</a></li>
<li class="level2"><a href="#faq_overhead">How much overhead?</a></li>
<li class="level2"><a href="#faq_performance">How much of a performance penalty?</a></li>
</ul>
</li>
<li class="level1"><a href="#compatibility">Compatibility</a></li>
<li class="level1"><a href="#section_future_work">Future Work</a></li>
<li class="level1"><a href="#changes">Changes from v.1.0</a></li>
<li class="level1"><a href="#license">License</a></li>
<li class="level1"><a href="#author">Author</a></li>
<li class="level1"><a href="#acknowledgements">Acknowledgements</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="intro"></a>
Overview</h1>
<p>This can also be found in the README file:</p>
<blockquote class="doxtable">
<p>ecuda Extended CUDA C++ API release 2.x</p>
<p>These are the release notes for ecuda version 2.</p>
<p>WHAT IS ECUDA?</p>
<p>ecuda is a C++ wrapper around the CUDA C API designed to closely resemble and be functionally equivalent to the C++ Standard Template Library (STL). Specifically: algorithms, containers, and iterators.</p>
<p>REQUIREMENTS</p>
<p>ecuda is a header only API, and the only pre-requisite library is the CUDA API version 5 or later. It should work with any C++ compiler, but has been developed and tested with several versions of gcc (most recently 4.8.4) and clang 3.6. The C++11 standard is optional, but is utilized if enabled. Visual Studio 2013 on Windows 10 was also successfully tested (see the INSTALLATION section below).</p>
<p>A correct setup should be able to compile the tools/print_device_info.cu program without issue. You can try:</p>
<div class="fragment"><div class="line">$ mkdir bin</div>
<div class="line">$ cd bin</div>
<div class="line">$ cmake ../tools</div>
<div class="line">$ make</div>
</div><!-- fragment --><p>to identify any issues. When run, the program prints out a pretty summary of the current system's GPU hardware and capabilities.</p>
<p>DOCUMENTATION:</p>
<ul>
<li><p class="startli">Documentation can be viewed online:</p>
<p class="startli"><a href="https://baderlab.github.io/ecuda/">https://baderlab.github.io/ecuda/</a></p>
</li>
<li>This is generated from the source files themselves using doxygen. The base directory contains a default doxygen.cfg file that will build a local copy of the documentation in the <code>docs/html</code> subdirectory. Make sure you have doxygen installed and run:</li>
</ul>
<div class="fragment"><div class="line">$ doxygen doxygen.cfg</div>
</div><!-- fragment --><p>INSTALLATION:</p>
<p>Linux/MacOS:</p>
<ul>
<li>As long as the include/ subdirectory is visible to the compiler, the API can be installed anywhere. A default install using CMake can be done by running:</li>
</ul>
<div class="fragment"><div class="line">$ cmake .</div>
<div class="line">$ sudo make install</div>
</div><!-- fragment --><p>This will copy the contents of the include/ subdirectory to ${CMAKE_INSTALL_PREFIX}/include (usually /usr/local/include).</p>
<p>Windows/Visual Studio:</p>
<ul>
<li>The latest free Visual Studio at the time of last update was Visual Studio Community 2015, but it is confirmed that CUDA 7.5 is not supported at this time. I managed to get everything working with Visual Studio Community 2013 on Windows 10. Here is my story:</li>
<li><p class="startli">Download and install Visual Studio Community 2013 from:</p>
<p class="startli"><a href="https://www.visualstudio.com/en-us/news/vs2013-community-vs.aspx">https://www.visualstudio.com/en-us/news/vs2013-community-vs.aspx</a></p>
</li>
<li><p class="startli">Download and install the Nvidia CUDA Toolkit from:</p>
<p class="startli"><a href="http://developer.nvidia.com/cuda-downloads">http://developer.nvidia.com/cuda-downloads</a></p>
<ul>
<li><p class="startli">The order is important since the CUDA installer integrates with any installed Visual Studio versions that it supports. Also note that in the successful configuration, only the following items in the CUDA installer's custom installation were left checked:</p>
<ul>
<li>CUDA Toolkit 7.5</li>
<li>CUDA Visual Studio Integration 7.5</li>
</ul>
<p class="startli">The following items were already installed on the test system with equal or greater version numbers:</p>
<ul>
<li>Graphics Driver</li>
<li>HD Audio Driver</li>
<li>NVIDIA GeForce Experience</li>
<li>PhysX System Software</li>
</ul>
<p class="startli">Do whatever makes the most sense for your situation.</p>
</li>
</ul>
</li>
<li>Start Visual Studio and load the ecuda.sln solution file.</li>
<li>The print_device_info project contains a source file that should build successfully at this point. Build the Release target with the x64 platform, and bin/x64/Release/print_device_info.exe should appear. Running this from the Windows command line should display a pretty summary of the current system's GPU hardware and capabilities.</li>
<li>When building a Debug target, Visual Studio's C++ Standard Library implementation does some kind of "iterator checking" that doesn't play nice with ecuda's custom iterators, causing erroneous assertion failures to get raised at runtime. Placing this at the beginning of a program will turn this off (and suppresses a warning about macro redefinition):</li>
</ul>
<div class="fragment"><div class="line"><span class="preprocessor">#pragma warning(disable:4005)</span></div>
<div class="line"><span class="preprocessor"></span><span class="preprocessor">#undef _HAS_ITERATOR_DEBUGGING</span></div>
<div class="line"><span class="preprocessor">#pragma warning(default:4005)</span></div>
</div><!-- fragment --><ul>
<li>Since ecuda is not actively developed on Windows, please report any issues or workarounds!</li>
</ul>
<p>BENCHMARKS AND EXAMPLES:</p>
<ul>
<li>The benchmarks/, test/ and t/ directories contain programs that were useful for development. They might be useful examples to see how ecuda can be used. Again, these were used during API development so they can be quite ugly and full of hacks.</li>
<li>Each subdirectory contains a CMakeList.txt file so building them should be easy if your system is properly set up. For example, to build the benchmarks/ folder, the following could be used:</li>
</ul>
<div class="fragment"><div class="line">$ mkdir -p bin/benchmarks</div>
<div class="line">$ cd bin/benchmarks</div>
<div class="line">$ cmake ../../benchmarks</div>
<div class="line">$ make</div>
</div><!-- fragment --><ul>
<li>Note that a file called local-config.cmake can be created in the release root directory that contains any system-specific CMake directives (e.g. nvcc compiler flags). The local-config.cmake.example file is an example of how this file might look.</li>
</ul>
<p>FILE DESCRIPTIONS:</p>
<pre>
  benchmarks/                Programs that compare cuda and ecuda performance.
  docs/                      Additional elements for building docs with doxygen.
  include/                   The ecuda API header files.
  t/                         Catch unit tests.
  test/                      Programs to loosely test elements of the API.
  tools/                     Utilities that utilize ecuda.
  CMakeLists.txt             CMake configuration file
  doxygen.cfg                doxygen configuration file
  ecuda.config               Qt Creator project file
  ecuda.creator              Qt Creator project file
  ecuda.files                Qt Creator project file
  ecuda.includes             Qt Creator project file
  ecuda.sln                  Visual Studio 2013 Solution file
  local-config.cmake.example Example file with additional CMake directives
  .gitignore                 local files to omit from version control
  LICENSE.txt                release license
  MANIFEST                   list of files under version control
  README                     this file
  VERSION                    current version of the API
</pre><p></p>
</blockquote>
<h1><a class="anchor" id="quick_ref"></a>
A Few Things You Should Know</h1>
<p>ecuda was written to be light-weight, intuitive and to follow the STL specification. Code should naturally follow modern C++ programming paradigms (e.g. RAII/SBRM, smart pointers). This can prevent many issues that arise from using the CUDA C API. That said, there are a few key, non-obvious concepts that you should know before using ecuda.</p>
<h2><a class="anchor" id="quick_ref_kernels"></a>
Containers as Kernel Arguments</h2>
<p>When passing base containers to a kernel function, declare the type as <code>Container::kernel_argument</code> or <code>Container::const_kernel_argument</code>.</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#af76006899e4498393c189e5dd2ef68e1">ecuda::vector&lt;double&gt;::const_kernel_argument</a> src, <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> dest );</div>
</div><!-- fragment --><p>This is not necessary for other container constructs.</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#ad0ffcd571700bbe2403095403cd445f9">ecuda::matrix&lt;double&gt;::const_row_type</a> src, <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a7947927ff51492aaa2e788151befca99">ecuda::matrix&lt;double&gt;::row_type</a> dest );</div>
</div><!-- fragment --><p>This should be done even in later versions of CUDA that support pass-by-reference, since one of the features of the <code>kernel_argument</code> subclass is that it strips away the reference-counting smart pointer from the container, sparing some registers.</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">const</span> <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a>&amp; src, <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a>&amp; dest ); <span class="comment">// NO!</span></div>
<div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#af76006899e4498393c189e5dd2ef68e1">ecuda::vector&lt;double&gt;::const_kernel_argument</a>&amp; src, <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a>&amp; dest ); <span class="comment">// OK :/</span></div>
</div><!-- fragment --><h2><a class="anchor" id="quick_ref_ops"></a>
Direct Access Operators</h2>
<p>Containers implements both <code>operator[]</code> and <code>operator()</code>. The latter should be used when directly accessing a single element in a multidimensional container. For linear containers like <a class="el" href="classecuda_1_1array.html" title="A fixed-size array stored in device memory. ">ecuda::array</a> and <a class="el" href="classecuda_1_1vector.html" title="A resizable vector stored in device memory. ">ecuda::vector</a> the operators are equivalent. The <code>at()</code> method can also be used. However, as with <code>std</code>:: containers, bounds checking is performed which is more expensive.</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a916ec29b2a5e8d6323e5bee8688cddda">ecuda::matrix&lt;double&gt;::kernel_argument</a> mat )</div>
<div class="line">{</div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line">  std::size_t x, y;</div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line">  <span class="keywordtype">double</span>&amp; val = mat[x][y];   <span class="comment">// slow</span></div>
<div class="line">  <span class="keywordtype">double</span>&amp; val = mat.<a class="code" href="classecuda_1_1matrix.html#ac88b00a0d29a03613fca18865c93cda4">at</a>(x,y); <span class="comment">// faster, kernel terminates and throws ecuda::cuda_error if x or y out of bounds</span></div>
<div class="line">  <span class="keywordtype">double</span>&amp; val = mat(x,y);    <span class="comment">// fastest</span></div>
<div class="line">  <span class="comment">// ...</span></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="quick_ref_contiguity"></a>
Memory Contiguity</h2>
<p>Be mindful that host copy commands that involve device memory require that memory to be contiguous. A compile-time assertion will be raised if you forget.</p>
<div class="fragment"><div class="line"><a class="code" href="classecuda_1_1matrix.html">ecuda::matrix&lt;double&gt;</a> deviceMatrix( 100, 100 );</div>
<div class="line">std::vector&lt;double&gt; vec( 100 );</div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( vec.begin(), vec.end(), deviceMatrix.get_row(22).begin() ); <span class="comment">// fine</span></div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( vec.begin(), vec.end(), deviceMatrix.get_column(22).begin() ); <span class="comment">// compile-time assertion CANNOT_USE_NONCONTIGUOUS_DEVICE_ITERATOR_AS_DESTINATION_FOR_COPY</span></div>
</div><!-- fragment --><p>This rule doesn't apply in device code.</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#af76006899e4498393c189e5dd2ef68e1">ecuda::vector&lt;double&gt;::const_kernel_argument</a> src, <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a916ec29b2a5e8d6323e5bee8688cddda">ecuda::matrix&lt;double&gt;::kernel_argument</a> dest )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t t = threadIdx.x;</div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( src.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), src.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), dest.<a class="code" href="classecuda_1_1matrix.html#a473a3209c4a77046c99b95833700769d">get_row</a>(t).begin() ); <span class="comment">// fine</span></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( src.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), src.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), dest.<a class="code" href="classecuda_1_1matrix.html#aa1697da9b4512e34dd46431be3204df2">get_column</a>(t).begin() ); <span class="comment">// also fine</span></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="quick_ref_macros"></a>
Macros</h2>
<table class="doxtable">
<tr>
<th>Macro </th><th>Description  </th></tr>
<tr>
<td>CUDA_CALL(...) </td><td>execute ... and if cudaSuccess is not returned, throw an <a class="el" href="classecuda_1_1cuda__error.html" title="Exception for CUDA API cudaError_t errors. ">ecuda::cuda_error</a>  </td></tr>
<tr>
<td><a class="el" href="global_8hpp.html#a948ab4bf2c74fff2fd55935897aff2c6">CUDA_CHECK_ERRORS()</a> </td><td>check for current CUDA error with cudaCheckLastError throw <a class="el" href="classecuda_1_1cuda__error.html" title="Exception for CUDA API cudaError_t errors. ">ecuda::cuda_error</a> if present  </td></tr>
<tr>
<td>CUDA_CALL_KERNEL_AND_WAIT(...) </td><td>combines the above two macros with an additional call to cudaDeviceSynchronize() that waits for the kernel ... to complete  </td></tr>
</table>
<h2><a class="anchor" id="quick_ref_hostemu"></a>
Host Emulation</h2>
<p>ecuda will behave appropriately if code is compiled for host only execution. This is useful for prototyping. You'll have to use the <code>__CUDACC__</code> define in a few places, however. Here's an example:</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="ecuda_8hpp.html">ecuda/ecuda.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> std::size_t N = 100000;</div>
<div class="line"></div>
<div class="line">__global__</div>
<div class="line"><span class="keywordtype">void</span> reverseVector( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> vec )</div>
<div class="line">{</div>
<div class="line"><span class="preprocessor">  #ifdef __CUDACC__</span></div>
<div class="line"><span class="preprocessor"></span>  <span class="keyword">const</span> std::size_t t = blockIdx.x*blockDim.x+threadIdx.x;</div>
<div class="line"><span class="preprocessor">  #else</span></div>
<div class="line"><span class="preprocessor"></span>  <span class="keywordflow">for</span>( std::size_t t = 0; t &lt; vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>(); ++t )</div>
<div class="line">  #endif</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; (vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()/2) ) {</div>
<div class="line">    <span class="keyword">const</span> std::size_t u = vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()-t-1;</div>
<div class="line">    <a class="code" href="namespaceecuda.html#abc2b93d379cadb08c39f2ae420afcf11">ecuda::swap</a>( vec[t], vec[u] );</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>* argv[] )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t THREADS = 512;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> deviceVector( N );</div>
<div class="line"></div>
<div class="line">  std::vector&lt;double&gt; hostVector( N );</div>
<div class="line">  <span class="comment">// ... initialize host vector values</span></div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( hostVector.begin(), hostVector.end(), deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>() );</div>
<div class="line"></div>
<div class="line"><span class="preprocessor">  #ifdef __CUDACC__</span></div>
<div class="line"><span class="preprocessor"></span>  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( reverseVector&lt;&lt;&lt;((N+THREADS-1)/THREADS),THREADS&gt;&gt;&gt;( deviceVector ) );</div>
<div class="line"><span class="preprocessor">  #else</span></div>
<div class="line"><span class="preprocessor"></span>  reverseVector( deviceVector )</div>
<div class="line">  <span class="preprocessor">#endif</span></div>
<div class="line"><span class="preprocessor"></span></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), deviceVector.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), hostVector.begin() );</div>
<div class="line">  <span class="comment">// ... host vector now contains result</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><p>If compiled with just the C++ compiler (e.g. g++), the resulting program will run as expected without the GPU.</p>
<h1><a class="anchor" id="example"></a>
Core Concepts and Examples</h1>
<h2><a class="anchor" id="example_array"></a>
Arrays</h2>
<p>Specification is identical to the C++11 std::array. More efficient when a sequence size is known at compile time. However, <a class="el" href="classecuda_1_1array.html" title="A fixed-size array stored in device memory. ">ecuda::array</a> doesn't require C++11.</p>
<p>This example requires CUDA &gt;= 7.0 and C++11 support since it uses &lt;array&gt;.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;array&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="ecuda_8hpp.html">ecuda/ecuda.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> std::size_t N = 100000;</div>
<div class="line"></div>
<div class="line">__global__</div>
<div class="line"><span class="keywordtype">void</span> squareRootArray( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1array.html#a3809f65553e4c7f3ec47bd2d5ba8ce5d">ecuda::array&lt;double,N&gt;::kernel_argument</a> arr )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t t = blockIdx.x*blockDim.x+threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; arr.<a class="code" href="classecuda_1_1array.html#a2ff59268df5ef067404c45403e3b15c2">size</a>() ) {</div>
<div class="line">    <span class="keywordtype">double</span> x = arr[t];</div>
<div class="line">    x = sqrt(x);</div>
<div class="line">    arr[t] = x;</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>* argv[] )</div>
<div class="line">{</div>
<div class="line"></div>
<div class="line">  <span class="keyword">const</span> std::size_t THREADS = 512;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1array.html">ecuda::array&lt;double,N&gt;</a> deviceArray;</div>
<div class="line"></div>
<div class="line">  std::array&lt;double,N&gt; hostArray;</div>
<div class="line">  <span class="comment">// ... initialize host array values</span></div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( hostArray.begin(), hostArray.end(), deviceArray.<a class="code" href="classecuda_1_1array.html#ab9511488943e44fb5b6e344b1e89d0ec">begin</a>() );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( squareRootArray&lt;&lt;&lt;((N+THREADS-1)/THREADS),THREADS&gt;&gt;&gt;( deviceArray ) );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceArray.<a class="code" href="classecuda_1_1array.html#ab9511488943e44fb5b6e344b1e89d0ec">begin</a>(), deviceArray.<a class="code" href="classecuda_1_1array.html#aad7a69116e73fac8114f404bd940716f">end</a>(), hostArray.begin() );</div>
<div class="line">  <span class="comment">// ... host array now contains result</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="example_vector"></a>
Vectors</h2>
<p>Specification is identical to std::vector. Will automatically grow in size to accomodate new data (e.g. <a class="el" href="classecuda_1_1vector.html#a3df939d3b084d053f22f4460f0fec9a2" title="Inserts value before position. ">ecuda::vector::insert</a>, <a class="el" href="classecuda_1_1vector.html#ae607e78a460ea63e371acb66e3602189" title="Replaces the contents of the container. ">ecuda::vector::assign</a>, <a class="el" href="classecuda_1_1vector.html" title="A resizable vector stored in device memory. ">ecuda::vector</a>:resize).</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="ecuda_8hpp.html">ecuda/ecuda.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> std::size_t N = 100000;</div>
<div class="line"></div>
<div class="line">__global__</div>
<div class="line"><span class="keywordtype">void</span> reverseVector( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> vec )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t t = blockIdx.x*blockDim.x+threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; (vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()/2) ) {</div>
<div class="line">    <span class="keyword">const</span> std::size_t u = vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()-t-1;</div>
<div class="line">    <a class="code" href="namespaceecuda.html#abc2b93d379cadb08c39f2ae420afcf11">ecuda::swap</a>( vec[t], vec[u] );</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>* argv[] )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t THREADS = 512;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> deviceVector( N );</div>
<div class="line"></div>
<div class="line">  std::vector&lt;double&gt; hostVector( N );</div>
<div class="line">  <span class="comment">// ... initialize host vector values</span></div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( hostVector.begin(), hostVector.end(), deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>() );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( reverseVector&lt;&lt;&lt;((N+THREADS-1)/THREADS),THREADS&gt;&gt;&gt;( deviceVector ) );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), deviceVector.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), hostVector.begin() );</div>
<div class="line">  <span class="comment">// ... host vector now contains result</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="example_matrix"></a>
Matrices</h2>
<p>A logical extension of an STL container to two dimensions. Memory is column-wise contiguous (i.e. (0,1) is followed by (0,2)). Separate threads should ideally access different columns for best memory coalescing. Utilizes memory allocation that is hardware aligned, so memory coalescing is more consistent. Rows and columns can be accessed and will have the same functionality as <a class="el" href="classecuda_1_1vector.html" title="A resizable vector stored in device memory. ">ecuda::vector</a>.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="ecuda_8hpp.html">ecuda/ecuda.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> std::size_t ROWS = 1000;</div>
<div class="line"><span class="keyword">const</span> std::size_t COLS = 1000;</div>
<div class="line"></div>
<div class="line">__global__</div>
<div class="line"><span class="keywordtype">void</span> sumMatrixColumns(</div>
<div class="line">  <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a301256d70b0f6a10804589d040c120c1">ecuda::matrix&lt;double&gt;::const_kernel_argument</a> mat,</div>
<div class="line">  <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> vec</div>
<div class="line">)</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t t = blockIdx.x*blockDim.x+threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; mat.<a class="code" href="classecuda_1_1matrix.html#ace012e99870f617eb65233cf90bb2039">number_columns</a>() ) {</div>
<div class="line">    vec[t] = <a class="code" href="namespaceecuda.html#a1165795685483cef9b23bb33bd48c829">ecuda::accumulate</a>( mat.<a class="code" href="classecuda_1_1matrix.html#aa1697da9b4512e34dd46431be3204df2">get_column</a>(t).begin(), mat.<a class="code" href="classecuda_1_1matrix.html#aa1697da9b4512e34dd46431be3204df2">get_column</a>(t).end(), <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(0) );</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>* argv[] )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t THREADS = 512;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1matrix.html">ecuda::matrix&lt;double&gt;</a> deviceMatrix( ROWS, COLS );</div>
<div class="line"></div>
<div class="line">  std::vector&lt;double&gt; hostVector( COLS );</div>
<div class="line">  <span class="comment">// ... initialize host vector values</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">for</span>( std::size_t i = 0; i &lt; ROWS; ++i ) {</div>
<div class="line">    std::random_shuffle( hostVector.begin(), hostVector.end() );</div>
<div class="line">    <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( hostVector.begin(), hostVector.end(), deviceMatrix[i].begin() );</div>
<div class="line">  }</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> deviceSums( COLS );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( sumMatrixColumns&lt;&lt;&lt;((COLS+THREADS-1)/THREADS),THREADS&gt;&gt;&gt;( deviceMatrix, deviceSums ) );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceSums.begin(), deviceSums.end(), hostVector.begin() );</div>
<div class="line">  <span class="comment">// ... host vector now contains result</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="example_cube"></a>
Cubes</h2>
<p>A logical extension of the <a class="el" href="classecuda_1_1matrix.html" title="A resizable matrix stored in device memory. ">ecuda::matrix</a> to to three dimensions. Memory is depth-wise contiguous (i.e. (0,1,2) is followed by (0,1,3)). Separate threads should ideally access different depths (and then different columns) for best memory coalescing. Utilizes memory allocation that is hardware aligned, so memory coalescing is more consistent. XY, XZ, and YZ slices can be accessed and will have the same functionality as <a class="el" href="classecuda_1_1matrix.html" title="A resizable matrix stored in device memory. ">ecuda::matrix</a>. Individual rows, columns, and depths can be accessed and will have the same functionality as <a class="el" href="classecuda_1_1vector.html" title="A resizable vector stored in device memory. ">ecuda::vector</a>.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;<a class="code" href="ecuda_8hpp.html">ecuda/ecuda.hpp</a>&gt;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">const</span> std::size_t ROWS = 100;</div>
<div class="line"><span class="keyword">const</span> std::size_t COLS = 100;</div>
<div class="line"><span class="keyword">const</span> std::size_t DEPS = 1024;</div>
<div class="line"></div>
<div class="line">__global__</div>
<div class="line"><span class="keywordtype">void</span> sumMatrix(</div>
<div class="line">  <span class="keyword">typename</span> <a class="code" href="classecuda_1_1cube.html#a7e3bd578d963d0aab9a95f7ed67a456d">ecuda::cube&lt;double&gt;::const_kernel_argument</a> cbe,</div>
<div class="line">  <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> vec</div>
<div class="line">)</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t t = blockIdx.x*blockDim.x+threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; cbe.<a class="code" href="classecuda_1_1cube.html#abb8e3fc3e3e73fd1545ca43b133aa3db">number_depths</a>() ) {</div>
<div class="line">    vec[t] = <a class="code" href="namespaceecuda.html#a1165795685483cef9b23bb33bd48c829">ecuda::accumulate</a>( cbe.<a class="code" href="classecuda_1_1cube.html#a25a97c19172e8647e58225e3d0978b1b">get_xy</a>(t).begin(), cbe.<a class="code" href="classecuda_1_1cube.html#a25a97c19172e8647e58225e3d0978b1b">get_xy</a>(t).end(), <span class="keyword">static_cast&lt;</span><span class="keywordtype">double</span><span class="keyword">&gt;</span>(0) );</div>
<div class="line">  }</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">int</span> main( <span class="keywordtype">int</span> argc, <span class="keywordtype">char</span>* argv[] )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> std::size_t THREADS = 512;</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1cube.html">ecuda::cube&lt;double&gt;</a> deviceCube( ROWS, COLS, DEPS );</div>
<div class="line">  <span class="keywordflow">for</span>( std::size_t i = 0; i &lt; ROWS; ++i ) {</div>
<div class="line">    <span class="keyword">typename</span> <a class="code" href="classecuda_1_1cube.html#aec0ef90f4fb323b0b27784268f00a4a8">ecuda::cube&lt;double&gt;::slice_yz_type</a> sliceYZ = deviceCube.get_yz(i);</div>
<div class="line">    std::vector&lt;double&gt; hostMatrix( COLS*DEPS );</div>
<div class="line">    <span class="comment">// ... initialize host matrix</span></div>
<div class="line">    <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( hostMatrix.begin(), hostMatrix.end(), sliceYZ.<a class="code" href="classecuda_1_1cube.html#a12106e50b8ff7df797876195c6e32914">begin</a>() );</div>
<div class="line">  }</div>
<div class="line"></div>
<div class="line">  <a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> deviceSums( DEPS );</div>
<div class="line"></div>
<div class="line">  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( sumMatrix&lt;&lt;&lt;((DEPS+THREADS-1)/THREADS),THREADS&gt;&gt;&gt;( deviceCube, deviceSums ) );</div>
<div class="line"></div>
<div class="line">  std::vector&lt;double&gt; hostSums( DEPS );</div>
<div class="line">  <a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceSums.begin(), deviceSums.end(), hostSums.begin() );</div>
<div class="line">  <span class="comment">// ... host vector now contains result</span></div>
<div class="line"></div>
<div class="line">  <span class="keywordflow">return</span> 0;</div>
<div class="line"></div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="example_host_alloc"></a>
Allocators</h2>
<p>ecuda uses custom STL allocators to handle device memory allocation (<a class="el" href="classecuda_1_1device__allocator.html" title="Allocator for device memory. ">ecuda::device_allocator</a> and <a class="el" href="classecuda_1_1device__pitch__allocator.html" title="Allocator for hardware aligned device memory. ">ecuda::device_pitch_allocator</a>). One normally doesn't need to worry about these.</p>
<p>However, the <a class="el" href="classecuda_1_1host__allocator.html" title="Allocator for page-locked host memory. ">ecuda::host_allocator</a> can be useful when allocating memory used as "staging" for transfers between the host and device (see the CUDA API cudaHostAlloc for more discussion). You can specify this as an allocator type when a host container is being used in this way.</p>
<div class="fragment"><div class="line"><a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> deviceVector( 1000 );</div>
<div class="line"><span class="comment">// ... do stuff</span></div>
<div class="line"></div>
<div class="line">std::vector&lt; double, ecuda::host_allocator&lt;double&gt; &gt; hostVector1( 1000 ); <span class="comment">// underlying memory allocated using cudaHostAlloc</span></div>
<div class="line">std::vector&lt;double&gt; hostVector2( 1000 ); <span class="comment">// underlying memory allocated using standard &quot;new&quot;</span></div>
<div class="line"></div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), deviceVector.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), hostVector1.begin() ); <span class="comment">// faster</span></div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">ecuda::copy</a>( deviceVector.<a class="code" href="classecuda_1_1vector.html#a349bbad8dcc59294fd9eb977569a2709">begin</a>(), deviceVector.<a class="code" href="classecuda_1_1vector.html#af0acbfb1488fe04fe136df3b6c5cd8c3">end</a>(), hostVector2.begin() ); <span class="comment">// slower</span></div>
<div class="line"></div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">std::copy</a>( hostVector1.begin(), hostVector1.begin()+500, hostVector1.begin()+500 ); <span class="comment">// slower</span></div>
<div class="line"><a class="code" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d">std::copy</a>( hostVector2.begin(), hostVector2.begin()+500, hostVector2.begin()+500 ); <span class="comment">// faster</span></div>
</div><!-- fragment --><h2><a class="anchor" id="example_exception"></a>
Exceptions</h2>
<p>ecuda will catch any errors that arise from calls to the CUDA C API and throw an <a class="el" href="classecuda_1_1cuda__error.html" title="Exception for CUDA API cudaError_t errors. ">ecuda::cuda_error</a> exception. This will also occur if a kernel crashes.</p>
<div class="fragment"><div class="line"><span class="keywordflow">try</span> {</div>
<div class="line">  <a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( kernelFunction&lt;&lt;&lt;THREADS&gt;&gt;&gt;( ... ) );</div>
<div class="line">} <span class="keywordflow">catch</span>( <a class="code" href="classecuda_1_1cuda__error.html">ecuda::cuda_error</a>&amp; ex ) {</div>
<div class="line">  std::cerr &lt;&lt; <span class="stringliteral">&quot;kernel failed: &quot;</span> &lt;&lt; ex.what() &lt;&lt; <span class="stringliteral">&quot; (code: &quot;</span> &lt;&lt; ex.<a class="code" href="classecuda_1_1cuda__error.html#a1343dee5cde6ea44c14545f7a3b7cef8">get_error_code</a>() &lt;&lt; <span class="stringliteral">&quot;)&quot;</span> &lt;&lt; std::endl;</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="example_events"></a>
Events</h2>
<p>A wrapper around CUDA event objects called <a class="el" href="classecuda_1_1event.html">ecuda::event</a> makes these more C++-like.</p>
<div class="fragment"><div class="line"><span class="comment">// record kernel execution time</span></div>
<div class="line"><a class="code" href="classecuda_1_1event.html">ecuda::event</a> start, stop;</div>
<div class="line"></div>
<div class="line">start.<a class="code" href="classecuda_1_1event.html#aea6c8159da636ccf4481460b97c1781f">record</a>(); <span class="comment">// record start time</span></div>
<div class="line">myKernel&lt;&lt;&lt;10,1000&gt;&gt;&gt;( ... );</div>
<div class="line">stop.<a class="code" href="classecuda_1_1event.html#aea6c8159da636ccf4481460b97c1781f">record</a>(); <span class="comment">// record stop time</span></div>
<div class="line">stop.<a class="code" href="classecuda_1_1event.html#aa3c2ce52eaf99b88550a0dfcb79d077f">synchronize</a>(); <span class="comment">// kernel execution is asynchronous, wait until it finishes</span></div>
<div class="line"></div>
<div class="line">std::cerr &lt;&lt; <span class="stringliteral">&quot;EXECUTION TIME: &quot;</span> &lt;&lt; ( stop-start ) &lt;&lt; <span class="stringliteral">&quot;milliseconds&quot;</span> &lt;&lt; std::endl;</div>
</div><!-- fragment --><h1><a class="anchor" id="faq"></a>
Frequently Asked Questions</h1>
<p>At this point, this section is really an "anticipated" FAQ.</p>
<h2><a class="anchor" id="faq_thrust"></a>
Why not Thrust?</h2>
<p>The <a href="http://docs.nvidia.com/cuda/thrust/">Thrust library</a> is officially supported by NVidia and is similar in that it makes CUDA more C++ friendly. However, the emphasis is quite different in that it aims to parallelize common algorithms like <code>sort</code>. It also features only two containers: <code>thrust::host_vector</code> and <code>thrust::device_vector</code>.</p>
<p>ecuda is focused more on the data structures themselves, making them easier to manipulate in device code and providing an intuitive relationship between device and host memory (and code).</p>
<p>Whether you use ecuda or Thrust (or both) depends on the focus of your project.</p>
<p>Good task for Thrust:</p>
<div class="fragment"><div class="line"><span class="comment">// I have 1000 measurements from 1000 experiments, and I want to sort each experiment</span></div>
<div class="line"><span class="keywordflow">for</span>( std::size_t i = 0; i &lt; 1000; ++i ) {</div>
<div class="line">  std::vector&lt;double&gt; measurements( 1000 );</div>
<div class="line">  <span class="comment">// ... load measurements for i-th experiment</span></div>
<div class="line">  thrust::sort( measurements.begin(), measurements.end() ); <span class="comment">// parallelized!</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>Good task for ecuda:</p>
<div class="fragment"><div class="line"><span class="comment">// I have 1000 measurements from 1000 experiments, and I want to run my fancy stats on each experiment</span></div>
<div class="line"><a class="code" href="classecuda_1_1matrix.html">ecuda::matrix&lt;double&gt;</a> data( 1000, 1000 );</div>
<div class="line"><a class="code" href="classecuda_1_1vector.html">ecuda::vector&lt;double&gt;</a> result( 1000 );</div>
<div class="line"><span class="comment">// ... load measurements</span></div>
<div class="line"><a class="code" href="global_8hpp.html#acfbe9b5a1983c4b6158105608ec27852">CUDA_CALL_KERNEL_AND_WAIT</a>( runStatistics&lt;&lt;&lt;1,1000&gt;&gt;&gt;( data, result ) );</div>
<div class="line"></div>
<div class="line">__global__void runStatistics( <span class="keyword">const</span> <a class="code" href="classecuda_1_1matrix.html#a916ec29b2a5e8d6323e5bee8688cddda">ecuda::matrix&lt;double&gt;::kernel_argument</a> data, <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> result )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">int</span> t = threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; data.<a class="code" href="classecuda_1_1matrix.html#ace012e99870f617eb65233cf90bb2039">number_columns</a>() ) {</div>
<div class="line">    <span class="keywordtype">double</span> fancyStat;</div>
<div class="line">    <a class="code" href="classecuda_1_1matrix.html#a6206e8f8dfd5a5971cc066ad48aa8ee5">ecuda::matrix&lt;double&gt;::const_column_type</a> measurements = data.<a class="code" href="classecuda_1_1matrix.html#aa1697da9b4512e34dd46431be3204df2">get_column</a>(t);</div>
<div class="line">    <span class="comment">// ... calculate fancy stat</span></div>
<div class="line">    result[t] = fancyStat;</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h2><a class="anchor" id="faq_overhead"></a>
How much overhead?</h2>
<p>Ideally none. ecuda does pray that the compiler will help in this. In some cases, additional overhead is not easily avoidable. For example:</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a916ec29b2a5e8d6323e5bee8688cddda">ecuda::matrix&lt;int64_t&gt;::kernel_argument</a> mat1, <span class="keyword">typename</span> <a class="code" href="classecuda_1_1matrix.html#a916ec29b2a5e8d6323e5bee8688cddda">ecuda::matrix&lt;double&gt;::kernel_argument</a> mat2 );</div>
</div><!-- fragment --><p>will never beat:</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> kernelFunction( int64_t* mat1, <span class="keywordtype">double</span>* mat2, <span class="keyword">const</span> <span class="keywordtype">size_t</span> pitch, <span class="keyword">const</span> <span class="keywordtype">size_t</span> nr, <span class="keyword">const</span> <span class="keywordtype">size_t</span> nc );</div>
</div><!-- fragment --><p>in the case where it is known that both matrices have the same dimension. This has never been an issue for me in practice.</p>
<h2><a class="anchor" id="faq_performance"></a>
How much of a performance penalty?</h2>
<p>None where it matters, some where it shouldn't. In cases where ecuda code takes longer to execute, it is probably worth it in terms of safety and consistency. For example:</p>
<div class="fragment"><div class="line"><a class="code" href="classecuda_1_1matrix.html">ecuda::matrix&lt;double&gt;</a> mat( 100, 100 );</div>
<div class="line"><span class="comment">/// ... set values</span></div>
</div><!-- fragment --><p>is slower than:</p>
<div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> rows = 100;</div>
<div class="line"><span class="keyword">const</span> <span class="keywordtype">size_t</span> cols = 100;</div>
<div class="line"><span class="keywordtype">double</span>* mat;</div>
<div class="line"><span class="keywordtype">size_t</span> pitch;</div>
<div class="line"><a class="code" href="global_8hpp.html#a6694bb1be0e7de8ed06a4bdc2ea374f1">CUDA_CALL</a>( cudaMalloc2D( &amp;mat, &amp;pitch, cols*<span class="keyword">sizeof</span>(<span class="keywordtype">double</span>), rows ) );</div>
<div class="line"><span class="comment">/// ... set values</span></div>
</div><!-- fragment --><p>but only because the former will always initialize the contents (e.g. with a <a class="el" href="namespaceecuda.html#ad434d4d608702c94e707a00c84eef984" title="Re-implementation of CUDA API function cudaMemset that enforces a single-byte value. ">cudaMemset()</a> call where it makes sense).</p>
<p>Within a kernel function, typical data access and manipulation will run identically. For example:</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> reverseSequence( <span class="keyword">typename</span> <a class="code" href="classecuda_1_1vector.html#a18ba7cbc4f9ebfee1d5ec8cbac83be4d">ecuda::vector&lt;double&gt;::kernel_argument</a> v )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">size_t</span> t = threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; (v.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()/2) ) <a class="code" href="namespaceecuda.html#abc2b93d379cadb08c39f2ae420afcf11">ecuda::swap</a>( v[t], v[vec.<a class="code" href="classecuda_1_1vector.html#ad16a3e7f04d5fabb57880ab06aee0dcb">size</a>()-t-1] );</div>
<div class="line">}</div>
</div><!-- fragment --><p>will run just as fast as:</p>
<div class="fragment"><div class="line">__global__ <span class="keywordtype">void</span> reverseSequence( <span class="keywordtype">double</span>* seq, <span class="keyword">const</span> <span class="keywordtype">size_t</span> len )</div>
<div class="line">{</div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">size_t</span> t = threadIdx.x;</div>
<div class="line">  <span class="keywordflow">if</span>( t &lt; (len/2) ) {</div>
<div class="line">    <span class="keywordtype">double</span> tmp = seq[t];</div>
<div class="line">    seq[t] = seq[len-t-1];</div>
<div class="line">    seq[u] = tmp;</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="compatibility"></a>
Compatibility</h1>
<p>The library has been tested and compiles successfully with CUDA versions 5.0, 5.5, 6.0, and 7.0 in combination with GCC 4.8.1 and 4.8.4. CUDA 6.0 and 7.0 with GCC 4.8.2 or Clang 3.5 and CUDA 7.5 with GCC 4.8.4 also compiled successfully but no example programs were tested. CUDA &lt;5.0 is not supported (specifically, CUDA 3.2, 4.0, 4.1, and 4.2 were tested and did not respect the preprocessor directives in __host__/__device__ methods that create a host-specific and device-specific implementation).</p>
<p>Some very cursory tests with Windows 10, Visual Studio 2013, and CUDA 7.5 were also done successfully. Unlike with Linux, ecuda has not been used in a production setting on Windows, however.</p>
<h1><a class="anchor" id="section_future_work"></a>
Future Work</h1>
<p>I've been developing and using ecuda in a production setting performing scientific computing that is heavily focused on statistics and information theory. All of the problems with version 1.0 have been addressed in this release and I'm fairly confident in its robustness at this point.</p>
<p>A fixed-size matrix and cube (like std::vector is to std::array) could potentially be useful. I'll likely add it when I actually need it.</p>
<p>Hopefully, any future work will be confined to bug fixes or addressing user difficulties.</p>
<h1><a class="anchor" id="changes"></a>
Changes from v.1.0</h1>
<p>The entire API was refined based on lessons learned. Broadly, the changes were:</p>
<ul>
<li>Removal of container operator&lt;&lt; and operator&gt;&gt; to transfer between host and device memory. The <a class="el" href="namespaceecuda.html#ad79c20b551be33bea5f0b62fba14434d" title="Replacement for std::copy. ">ecuda::copy</a> function (equivalent to std::copy) should now be used. </li>
<li>Any container passed to a kernel function as an argument should be declared as Container::kernel_argument. </li>
<li>Copy constructors now work as expected (memory is allocated and the contents copied). </li>
<li>Container at() method now performs bounds-checking (which is more consistent with the STL specification), and direct access to a particular container element is now done using operator().</li>
</ul>
<h1><a class="anchor" id="license"></a>
License</h1>
<p>The <em>ecuda</em> library is open source and released under the FreeBSD license.</p>
<pre class="fragment">Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

The views and conclusions contained in the software and documentation are those
of the authors and should not be interpreted as representing official policies,
either expressed or implied, of the FreeBSD Project.
</pre><h1><a class="anchor" id="author"></a>
Author</h1>
<p>Scott Zuyderduyn, Ph.D.<br/>
 Postdoctoral Research Fellow<br/>
 Bader Lab<br/>
 The University of Toronto<br/>
 <br/>
 Email: scott.zuyderduyn *at* utoronto.ca</p>
<h1><a class="anchor" id="acknowledgements"></a>
Acknowledgements</h1>
<p>The resources and expertise of the <a href="http://www.scinethpc.ca">SciNet</a> supercomputing centre at The University of Toronto which is home to several GPU clusters. I used these extensively for my own scientific research (which spawned the creation of this library).</p>
<p>The support of the <a href="http://baderlab.org/">Bader Lab</a>, part of the <a href="http://tdccbr.med.utoronto.ca">Donnelly Centre for Cellular and Biomolecular Research</a> at The University of Toronto, where I am currently a postdoctoral fellow. </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Jan 28 2016 14:05:58 for Extended CUDA Library (ecuda) by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
